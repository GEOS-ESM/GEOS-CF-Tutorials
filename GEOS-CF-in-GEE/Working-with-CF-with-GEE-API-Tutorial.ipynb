{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a806f450",
   "metadata": {},
   "source": [
    "# GEOS-CF in Google Earth Engine\n",
    "\n",
    "\n",
    "This notebook details methods for interacting with GEOS Composition Forecast (GEOS-CF) model diagnostics via the Google Earth Engine (GEE) Python API.\n",
    "\n",
    "This API allows users to access a huge repository of data from GEE and use GEE functions to run fast server-side functions to manipulate data.\n",
    "\n",
    "The strength of the GEE Python API is that users can pull data client-side and interact with selected fields within Pandas dataframes and other useful data structures.\n",
    "\n",
    "This notebook will go through the following steps:\n",
    "\n",
    "- Access GEOS-CF historical estimates and TROPOMI observations from the GEE data repository\n",
    "- Turning an image collection into a Pandas dataframe at a selected point-of-interest\n",
    "- Merging GEOS-CF model estimates of NO2 with TROPOMI observations of NO2\n",
    "- Visualizing these data as images on an interactive folium map\n",
    "- Visualizing these data using interactive plotly plots\n",
    "- Gap-filling TROPOMI observations of tropospheric NO2 data with an XGBoost model\n",
    "\n",
    "\n",
    "Notebook created by Callum Wayman, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4da1d",
   "metadata": {},
   "source": [
    "## Importing Required Modules\n",
    "\n",
    "The Python Earth Engine API requires installation, authentican, and initialization in order to run in a Python environment. These steps can be accomplished in command line, or within Python code. \n",
    "\n",
    "More information on these steps can be found [here.](https://developers.google.com/earth-engine/guides/python_install)\n",
    "\n",
    "Other modules required for this tutorial are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7017b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=gsBko7f1vU7180r4ZUwlFQS2VzbK4UWVwiYci_Vkzv8&tc=pwPJDq5NDBfZtu40aveSPBpuiT_Y1x_jpjdoUyWwhSo&cc=Vq6SLYnm3AfZTd5nxmQi9et0S9z25h_DjX6GqGhK7Fk>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=gsBko7f1vU7180r4ZUwlFQS2VzbK4UWVwiYci_Vkzv8&tc=pwPJDq5NDBfZtu40aveSPBpuiT_Y1x_jpjdoUyWwhSo&cc=Vq6SLYnm3AfZTd5nxmQi9et0S9z25h_DjX6GqGhK7Fk</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AQlEd8xgLUCLoAO_fZeHySCF-L8nXQ1AurcfgR4J_yNiBQVlPef727-0dqs\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "\n",
    "#ee.Authenticate()#force=True)\n",
    "\n",
    "ee.Initialize(project='ee-callumwayman-cf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb33e6dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpyo\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from math import sqrt\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The 'nopython' keyword.*\")\n",
    "\n",
    "import folium\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "import plotly.express as px\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f86eff",
   "metadata": {},
   "source": [
    "## Importing Data from Google Earth Engine\n",
    "\n",
    "Two collections are imported in this tutorial. The GEOS-CF time-averaged hourly replay collection is being imported, and more information on this collection can be found [here.](https://developers.google.com/earth-engine/datasets/catalog/NASA_GEOS-CF_v1_rpl_tavg1hr)\n",
    "\n",
    "The other collection being imported is the Near Real-Time Nitrogen Dioxide image collection from the TROPOMI instrument. This collection offers observations of various atmospheric conditions and parameters, including NO2, which will be the focus of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "\n",
    "# GEE Data\n",
    "geosCf = ee.ImageCollection(\"NASA/GEOS-CF/v1/rpl/tavg1hr\")\n",
    "tropomi = ee.ImageCollection(\"COPERNICUS/S5P/NRTI/L3_NO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94b01c",
   "metadata": {},
   "source": [
    "## Turning Earth Engine Objects into Pandas Dataframes\n",
    "\n",
    "Google Earth Engine data is often presented in two object types: features and images.\n",
    "\n",
    "Features and images may be stacked into feature collections and image collections.\n",
    "\n",
    "These object types are extremely useful within GEE to manipulate large data sets quickly, however they offer some limitations in our ability to manipulate the data within when we use Python.\n",
    "\n",
    "For this reason, this tutorial will geographically subset the imported image collections and transform them into Pandas dataframes. More information on Pandas dataframes can be found [here.](https://pandas.pydata.org/pandas-docs/version/0.25.0/reference/frame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ee_array_to_df(arr, list_of_bands):\n",
    "    \"\"\"Transforms client-side ee.Image.getRegion array to pandas.DataFrame.\"\"\"\n",
    "    df = pd.DataFrame(arr)\n",
    "\n",
    "    # Rearrange the header.\n",
    "    headers = df.iloc[0]\n",
    "    df = pd.DataFrame(df.values[1:], columns=headers)\n",
    "\n",
    "    # Remove rows without data inside.\n",
    "    df = df[['longitude', 'latitude', 'time', *list_of_bands]].dropna()\n",
    "\n",
    "    # Convert the data to numeric values.\n",
    "    for band in list_of_bands:\n",
    "        df[band] = pd.to_numeric(df[band], errors='coerce')\n",
    "        \n",
    "    # Convert the time field into a datetime.\n",
    "    # Time values are stored differently for TROPOMI and GEOS-CF data\n",
    "    # Need to remove the time columns from GEOS-CF dataframes\n",
    "    if 'number' in list_of_bands[0]:\n",
    "        df['datetime'] = pd.to_datetime(df['time'], unit='ms').dt.strftime('%Y-%m-%d %H:%M')\n",
    "    else:\n",
    "        df['datetime'] = pd.to_datetime(df['time'], unit='ms')\n",
    "        # Remove time columns from GEOS-CF dataframes\n",
    "        df.pop('time')\n",
    "\n",
    "    # Keep the columns of interest.\n",
    "    df = df[['datetime',  *list_of_bands]]\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(columns='index', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c234cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ee_subset:\n",
    "    \"\"\"\n",
    "    A class with methods to create subsets of Earth Engine\n",
    "    image collections.\n",
    "      \n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    band_dict : dict\n",
    "        dictionary whose keys are band names and values are unit\n",
    "        conversion values\n",
    "    num_days : int\n",
    "        number of days to be subset\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    get_subset_collection\n",
    "        Returns a GEE collection subset for the number of days\n",
    "        specified.\n",
    "    get_point_df\n",
    "        Takes a GEE image collection and returns a dataframe subset for the \n",
    "        number of days at a specific set of coordinates.\n",
    "    \"\"\"\n",
    "    def __init__(self, band_dict, num_days):\n",
    "        # Save band names and unit conversion values\n",
    "        self.band_dict = band_dict\n",
    "        self.band_list = list(band_dict.keys())\n",
    "        \n",
    "        # Get Dates\n",
    "        # All subsets end at June 15th, 2023 for this tutorial\n",
    "        f_date_datetime = dt.datetime.strptime('2023-06-15', \"%Y-%m-%d\")\n",
    "        f_year = f_date_datetime.year\n",
    "        f_month = f_date_datetime.month\n",
    "        f_day = f_date_datetime.day\n",
    "        i_date_datetime = f_date_datetime - dt.timedelta(num_days)\n",
    "        i_year = i_date_datetime.year\n",
    "        i_month = i_date_datetime.month\n",
    "        i_day = i_date_datetime.day\n",
    "\n",
    "        # Initial date of interest (inclusive).\n",
    "        self.i_date = f'{i_year}-{i_month}-{i_day}'\n",
    "\n",
    "        # Final date of interest (exclusive).\n",
    "        self.f_date = f'{f_year}-{f_month}-{f_day}'\n",
    "    \n",
    "    def get_subset_collection(self, collection):\n",
    "        \"\"\"\n",
    "        Subsets a GEE collection and returns subset \n",
    "        with appropriate time-window and bands selected.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        collection : ee.imagecollection.ImageCollection\n",
    "            GEE image collection to be subset\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        coll_subset : ee.imagecollection.ImageCollection\n",
    "            Subset of collection\n",
    "        \"\"\"\n",
    "\n",
    "        # Select bands and dates for collection\n",
    "        coll_subset = collection.select(self.band_list).filterDate(self.i_date, self.f_date)\n",
    "\n",
    "        return coll_subset\n",
    "        \n",
    "    \n",
    "    def get_point_df(self, collection, lat, lon):\n",
    "        \"\"\"\n",
    "        Subsets a GEE collection and returns subset \n",
    "        dataframe for a specific set of coordinates.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        collection : ee.imagecollection.ImageCollection\n",
    "            GEE image collection to be subset\n",
    "        lat : int\n",
    "            Latitude coordinate for point of interest\n",
    "        lon : int\n",
    "            Longitude coordinate for point of interest\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        data_features: pandas.core.frame.DataFrame\n",
    "            Subset of collection returned as data frame\n",
    "            for selected bands, time window, and point of interest.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get subsetted collection\n",
    "        coll_subset = self.get_subset_collection(collection)\n",
    "        \n",
    "        # EE point from lat, lon\n",
    "        poi = ee.Geometry.Point(lon, lat)\n",
    "        \n",
    "        # Scale in meters\n",
    "        scale = 1000\n",
    "        \n",
    "        # Get the data for the pixel intersecting the point\n",
    "        data_poi = coll_subset.getRegion(poi, scale).getInfo()\n",
    "        \n",
    "        # Call function to turn data into dataframe\n",
    "        data_features = ee_array_to_df(data_poi, self.band_list)\n",
    "        \n",
    "        # Convert feature units to desired units for each band\n",
    "        for b in self.band_list:\n",
    "            data_features[b] = data_features[b]*self.band_dict[b]\n",
    "\n",
    "        return data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f3aa9",
   "metadata": {},
   "source": [
    "## Subsetting GEE Data\n",
    "\n",
    "Select the desired bands you wish to analyze from each collection. In this tutorial, we will be working with tropospheric column and surface level NO2 data.\n",
    "\n",
    "We select relevant CF and TROPOMI bands, lat/lon, and number of days and subset the data using the ee_subset class and associated methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set selected bands\n",
    "cfSurfBand = 'NO2' # mol mol-1\n",
    "cfTropBand = 'TROPCOL_NO2' # 1.0e15 molec cm-2\n",
    "tropNo2Band = 'tropospheric_NO2_column_number_density' # mol/m2\n",
    "\n",
    "# Create band dictionaries to store unit conversion information\n",
    "cf_chm_band_dict = {cfSurfBand: 1.0e9, cfTropBand: 10000*1e15/6.02e23, 'O3': 1.0e9, 'NOy': 1.0e9, 'PM25_RH35_GCC': 1}\n",
    "cf_met_band_dict = {'T10M': 1, 'ZPBL': 1, 'U10M': 1, 'V10M': 1, 'RH': 1}\n",
    "trop_band_dict = {tropNo2Band: 1}\n",
    "\n",
    "# Change to exact lat/lon for takoma rec\n",
    "lat = 38.97\n",
    "lon = -77.02\n",
    "\n",
    "# EE point from lat, lon\n",
    "poi = ee.Geometry.Point(lon, lat)\n",
    "\n",
    "#Number of days to visualize\n",
    "num_days = 300\n",
    "\n",
    "# Get subset GEE collection and subset Dataframe\n",
    "\n",
    "# GEOS-CF Chemistry\n",
    "cf_chm_subset = ee_subset(cf_chm_band_dict, num_days)\n",
    "cf_chm_subset_collection = cf_chm_subset.get_subset_collection(geosCf)\n",
    "cf_chm_features = cf_chm_subset.get_point_df(geosCf, lat, lon)\n",
    "\n",
    "# GEOOS-CF Meteorology\n",
    "cf_met_subset = ee_subset(cf_met_band_dict, num_days)\n",
    "cf_met_subset_collection = cf_met_subset.get_subset_collection(geosCf)\n",
    "cf_met_features = cf_met_subset.get_point_df(geosCf, lat, lon)\n",
    "\n",
    "# TROPOMI chemistry\n",
    "trop_subset = ee_subset(trop_band_dict, num_days)\n",
    "trop_subset_collection = trop_subset.get_subset_collection(tropomi)\n",
    "trop_features = trop_subset.get_point_df(tropomi, lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a856c7a",
   "metadata": {},
   "source": [
    "## Mapping GEOS-CF and TROPOMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f40dd",
   "metadata": {},
   "source": [
    "Using the folium package, we can create leaflet maps that allow us to view the data we have accessed from the GEE data repository.\n",
    "\n",
    "This section will also explore the use of plotly plots to show a time-series of the subsetted data from GEOS-CF and TROPOMI at the point of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2092c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a point of interest (POI) with a buffer zone of 1000 km around POI.\n",
    "roi = poi.buffer(1e6)\n",
    "\n",
    "# Reduce the LST collection by mean.\n",
    "cf_img = cf_chm_subset_collection.mean()\n",
    "\n",
    "# Adjust for scale factor.\n",
    "cf_img = cf_img.select(cfSurfBand).multiply(cf_chm_band_dict[cfSurfBand])\n",
    "\n",
    "my_map = folium.Map(location=[lat, lon], zoom_start=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e01d3",
   "metadata": {},
   "source": [
    "### Adding a Useful Folium Method\n",
    "\n",
    "The below function creates a new folium method and adds it to the folium.Map class.\n",
    "\n",
    "This function receives an Earth Engine image object and creates a set of folium tiles from that image which can be added to the map.\n",
    "\n",
    "The new method allows us to easily visualize images on a basemap as we might in the GEE code editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
    "    \"\"\"\n",
    "    Adds a method for displaying Earth Engine image tiles to folium map.\n",
    "    \n",
    "    Parameters\n",
    "        ----------\n",
    "        ee_image_object : ee.image.Image\n",
    "            GEE image collection to be subset\n",
    "        vis_params : dict\n",
    "            Dictionary of GEE visualization parameters\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "    folium.raster_layers.TileLayer(\n",
    "        tiles=map_id_dict['tile_fetcher'].url_format,\n",
    "        attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "        name=name,\n",
    "        overlay=True,\n",
    "        control=True\n",
    "    ).add_to(self)\n",
    "    \n",
    "# Add Earth Engine drawing method to folium.\n",
    "folium.Map.add_ee_layer = add_ee_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad71c57",
   "metadata": {},
   "source": [
    "### Creating an Interactive Time-Series Plot\n",
    "\n",
    "In this section, we create and save a plotly plot showing a time-series of tropospheric NO2 data from GEOS-CF and TROPOMI.\n",
    "\n",
    "The interactive plot will be added to a below folium map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the figure object\n",
    "fig=make_subplots(specs=[[{\"secondary_y\":True}]])\n",
    "\n",
    "# Create the first plotly trace showing GEOS-CF tropospheric NO2\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "    x=cf_chm_features['datetime'],\n",
    "    y=cf_chm_features[cfTropBand],\n",
    "    name=\"Tropospheric NO2 (mol/m^2)\",\n",
    "    mode='lines+markers',\n",
    "    hoverinfo='y',\n",
    "    line = dict(color='indigo', width=3)\n",
    "     ),\n",
    "    secondary_y=False)\n",
    "\n",
    "# Create the second plotly trace showing TROPOMI tropospheric NO2\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "    x=trop_features['datetime'],\n",
    "    y=trop_features[tropNo2Band],\n",
    "    name=\"TROPOMI NO2 (mol/m^2)\",\n",
    "    mode='markers',\n",
    "    hoverinfo='y',\n",
    "    line = dict(color='red', width=3)\n",
    "     ),\n",
    "    secondary_y=False)\n",
    "\n",
    "# Update figure axis aesthetics and labels\n",
    "fig.update_layout(hoverlabel_bgcolor='#DAEEED',  #Change the background color of the tooltip to light gray\n",
    "             title_text=\"GEOS-CF Tropospheric NO2 Replay\", #Add a chart title\n",
    "             title_font_family=\"Times New Roman\",\n",
    "             title_font_size = 20,\n",
    "             title_font_color=\"darkblue\", #Specify font color of the title\n",
    "             title_x=0.5, #Specify the title position\n",
    "             xaxis=dict(\n",
    "                    tickfont_size=10,\n",
    "                    tickangle = 270,\n",
    "                    showgrid = True,\n",
    "                    zeroline = True,\n",
    "                    showline = True,\n",
    "                    showticklabels = True,\n",
    "                    #dtick=86400000,\n",
    "                    dtick=\"M1\",\n",
    "                    tickformat=\"%m/%d\\n%Y\"\n",
    "                    ),\n",
    "             legend = dict(orientation = 'h', xanchor = \"center\", x = 0.72, y= 1), #Adjust legend position\n",
    "             yaxis_title='Tropospheric NO2 (mol/m^2)')\n",
    "\n",
    "# Set scientific notation format for y-axis\n",
    "fig.update_yaxes(exponentformat='e')\n",
    "\n",
    "# Write the image to a local html file\n",
    "fig.write_html('surface_no2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select tropospheric NO2 and date range for GEOS-CF and scale to ppbv\n",
    "cf_trop_img = cf_chm_subset_collection.select(cfTropBand).filterDate('2023-05-14', '2023-05-15').mean().multiply(cf_chm_band_dict[cfTropBand])\n",
    "\n",
    "# Select tropospheric NO2 and date range for TROPOMI\n",
    "trop_img = trop_subset_collection.filterDate('2023-05-14', '2023-05-15').mean()\n",
    "\n",
    "# Set visualization parameters for NO2\n",
    "cf_vis_params = {\n",
    "    'min': 1,'max': 40,\n",
    "    'palette': ['white', 'purple'],\n",
    "    'opacity': 0.5\n",
    "}\n",
    "\n",
    "# Visualization parameters for tropospheric column NO2\n",
    "visTrop = {'min': 1e-6,\n",
    "    'max': 1e-4,\n",
    "    'palette': ['white', 'purple'],\n",
    "    'opacity': 0.5\n",
    "          }\n",
    "\n",
    "# Create a map.\n",
    "lat, lon = lat, lon\n",
    "my_map = folium.Map(location=[lat, lon], zoom_start=10)\n",
    "\n",
    "# Add the cf and tropomi data to the map object.\n",
    "my_map.add_ee_layer(cf_trop_img, visTrop, 'GEOS-CF NO2')\n",
    "my_map.add_ee_layer(trop_img, visTrop, 'TROPOMI NO2')\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "my_map.add_child(folium.LayerControl())\n",
    "\n",
    "# Set the plotly-generated html file into a html snippet\n",
    "html=\"\"\"\n",
    "    <iframe src=\\\"\"\"\" + 'surface_no2.html' + \"\"\"\\\" width=\"850\" height=\"400\"  frameborder=\"0\">    \n",
    "    \"\"\"\n",
    "    \n",
    "# Create pop-up with added plotly html snippet\n",
    "popup = folium.Popup(folium.Html(html, script=True))\n",
    "\n",
    "# Add marker to map for point of interest\n",
    "marker = folium.Marker([lat, lon],\n",
    "                       popup=popup).add_to(my_map)\n",
    "\n",
    "# Display the map.\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1865e5",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Consider a 3-hour CF window around tropomi overpass time instead of 1 to 1 correspondance.\n",
    "\n",
    "Go back to old forecasts, how well did forecasts predict what tropomi would look like? 1 day out? 5 days out?\n",
    "\n",
    "overfitting check can be the mean bias in training vs testing\n",
    "\n",
    "target tropospheric column and then derive to surface and compare to openaq - done\n",
    "\n",
    "use xgboost model to predict difference between model and obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64affec",
   "metadata": {},
   "source": [
    "## XGBoost Model\n",
    "\n",
    "In this section, we will use an XGBoost model to gap-fill TROPOMI observations of tropospheric column NO2.\n",
    "\n",
    "This gap-filled data set can then be use to create an estimate of surface level NO2 values derived from observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge chemistry and met features\n",
    "features = cf_chm_features.merge(cf_met_features,on='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18428a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = features.resample('3H', on='datetime').mean()\n",
    "samp.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable is observation in ppbv\n",
    "target = trop_features.copy()\n",
    "target['datetime'] = pd.to_datetime(target['datetime'])\n",
    "target[\"datetime\"] = target[\"datetime\"].dt.round(\"H\")\n",
    "#target.pop('time')\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=samp\n",
    "\n",
    "#print(features, target)\n",
    "\n",
    "# also add target observation\n",
    "#merged = features.merge(target,on='datetime', how='left')\n",
    "merged = features.merge(target, on='datetime', how='right')\n",
    "#merged = pd.merge_asof(features, target, on='datetime', direction='nearest')\n",
    "merged.fillna(value=np.nan, inplace=True)\n",
    "#merged.resample('3H', on='datetime').mean()\n",
    "#merged.reset_index(inplace=True)\n",
    "#merged.pop('index')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "merged.plot(x = 'datetime', y = cfTropBand, ax = ax, label = 'GEOS-CF Tropospheric NO2') \n",
    "merged.plot(x = 'datetime', y = tropNo2Band, ax = ax, c = 'r', label = 'TROPOMI Tropospheric NO2', zorder=2)\n",
    "ax.set_xlim([merged.datetime.min(), merged.datetime.max()])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae39d7",
   "metadata": {},
   "source": [
    "- need to create a data set of random points across the CF grid and tropomi grid\n",
    "\n",
    "- each row has lat/lon as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41992ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y for XGBoost\n",
    "chm_vars = list(cf_chm_band_dict.keys())\n",
    "met_vars = list(cf_met_band_dict.keys())\n",
    "feature_names = chm_vars+met_vars\n",
    "X = merged[feature_names]\n",
    "Y = merged[[tropNo2Band]] * 10000\n",
    "\n",
    "X_arr = X.to_numpy()\n",
    "Y_arr = Y.to_numpy()[:,0]\n",
    "\n",
    "print(X_arr.shape, Y_arr.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, Y_arr, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, missing=np.nan, feature_names=feature_names)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, missing=np.nan, feature_names=feature_names)\n",
    "\n",
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43980b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "print('BEGIN TRAINING')\n",
    "train = xgb.DMatrix(X,Y)\n",
    "params = {'booster' : 'gbtree', 'eta': 0.3, 'verbosity': 2}\n",
    "model = xgb.train(params,dtrain)\n",
    "train_pred = model.predict(dtrain)\n",
    "prediction = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics (on the trained data - this is cheating!)\n",
    "yflat = np.array(y_train).ravel()\n",
    "print('r2 = {:.2f}'.format(r2_score(yflat,train_pred)))\n",
    "print('nrmse = {:.2f}'.format( sqrt(mean_squared_error(yflat,train_pred))/np.std(yflat)))\n",
    "print('nmb = {:.2f}'.format(np.sum(train_pred-yflat)/np.sum(yflat)))\n",
    "\n",
    "# plot\n",
    "dat = pd.DataFrame({'obs':yflat,'pred':train_pred})\n",
    "dat['date'] = merged['datetime']\n",
    "dat['orig'] = merged[cfTropBand]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ax.plot(dat['date'],dat['obs'],color='black',label='Observed')\n",
    "#ax.plot(dat['date'],dat['orig'],color='blue',label='GEOS-CF')\n",
    "ax.plot(dat['date'],dat['pred'],color='red',label='GEOS-CF + XGBoost')\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yflat = np.array(y_test).ravel()\n",
    "print('r2 = {:.2f}'.format(r2_score(yflat,prediction)))\n",
    "print('nrmse = {:.2f}'.format( sqrt(mean_squared_error(yflat,prediction))/np.std(yflat)))\n",
    "print('nmb = {:.2f}'.format(np.sum(prediction-yflat)/np.sum(yflat)))\n",
    "\n",
    "# plot\n",
    "dat = pd.DataFrame({'obs':yflat,'pred':prediction})\n",
    "dat['date'] = merged['datetime']\n",
    "dat['orig'] = merged[cfTropBand]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ax.plot(dat['date'],dat['obs'],color='black',label='Observed')\n",
    "#ax.plot(dat['date'],dat['orig'],color='blue',label='GEOS-CF')\n",
    "ax.plot(dat['date'],dat['pred'],color='red',label='GEOS-CF + XGBoost')\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e13ae4",
   "metadata": {},
   "source": [
    "### Tuning the XGBoost Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compute MAE\n",
    "mae_baseline = mean_absolute_error(y_test, prediction)\n",
    "mae_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "\n",
    "params['eval_metric'] = \"mae\"\n",
    "\n",
    "# Set a high number of boost rounds\n",
    "# We hope to find optimal number of rounds before this\n",
    "num_boost_round = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e333891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce027080",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results['test-mae-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try wider intervals with a larger step between\n",
    "# each value and then narrow it down. Here after several\n",
    "# iteration I found that the optimal value was in the\n",
    "# following ranges.\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "gridsearch_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=0\n",
    "    );    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min();\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin();\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "        print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640576ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91332c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49165d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d61e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ab572",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# This can take some time…\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None \n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))    \n",
    "    # We update our parameters\n",
    "    params['eta'] = eta    \n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['mae'],early_stopping_rounds=10)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d008cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54485301",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ae69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cb309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-train with new hyperparameters\n",
    "\n",
    "model = xgb.train(params,dtrain)\n",
    "train_pred = model.predict(dtrain)\n",
    "prediction = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e099e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics (on the trained data - this is cheating!)\n",
    "yflat = np.array(y_train).ravel()\n",
    "print('r2 = {:.2f}'.format(r2_score(yflat,train_pred)))\n",
    "print('nrmse = {:.2f}'.format( sqrt(mean_squared_error(yflat,train_pred))/np.std(yflat)))\n",
    "print('nmb = {:.2f}'.format(np.sum(train_pred-yflat)/np.sum(yflat)))\n",
    "\n",
    "# plot\n",
    "dat = pd.DataFrame({'obs':yflat/1000,'pred':train_pred/1000})\n",
    "dat['date'] = merged['datetime']\n",
    "dat['orig'] = merged[cfTropBand]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ax.plot(dat['date'],dat['obs'],color='black',label='Observed')\n",
    "ax.plot(dat['date'],dat['pred'],color='red',label='GEOS-CF + XGBoost')\n",
    "ax.set_ylabel('Tropospheric NO2 (mol/m^2)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85662a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "yflat = np.array(y_test).ravel()\n",
    "print('r2 = {:.2f}'.format(r2_score(yflat,prediction)))\n",
    "print('nrmse = {:.2f}'.format( sqrt(mean_squared_error(yflat,prediction))/np.std(yflat)))\n",
    "print('nmb = {:.2f}'.format(np.sum(prediction-yflat)/np.sum(yflat)))\n",
    "\n",
    "# plot\n",
    "dat = pd.DataFrame({'obs':yflat,'pred':prediction})\n",
    "dat['date'] = merged['datetime']\n",
    "dat['orig'] = merged[cfTropBand]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ax.plot(dat['date'],dat['obs'],color='black',label='Observed')\n",
    "ax.plot(dat['date'],dat['pred'],color='red',label='GEOS-CF + XGBoost')\n",
    "ax.set_ylabel('Tropospheric NO2 (mol/m^2)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad323ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to derive shapley values\n",
    "# Need to load JS vis in the notebook\n",
    "#import shap\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "i = 100\n",
    "shap.force_plot(explainer.expected_value, shap_values[i], features=X.loc[i], feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features=X, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb6617",
   "metadata": {},
   "source": [
    "## Explaining the plot above\n",
    "\n",
    "Interpretation is that a high value of a feature in red contributes to either higher or lower tropomi derived sfc no2. For example, high NO2 from GEOS-CF usually corresponds to a higher predicted sfc NO2, however higher ZPBL corresponds to a lower sfc NO2.\n",
    "\n",
    "The goal of SHAP is to explain the prediction of an instance x by computing the contribution of each feature to the prediction. [...] SHAP feature importance is an alternative to permutation feature importance. There is a big difference between both importance measures: Permutation feature importance is based on the decrease in model performance. SHAP is based on magnitude of feature attributions.\n",
    "(https://datascience.stackexchange.com/questions/99650/difference-between-feature-effect-and-feature-importance)\n",
    "\n",
    "In other words, feature importance explains contribution to goodness of fit, and SHAP value explains contribution to predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply predictor to full input dataset\n",
    "data = features.copy()[chm_vars+met_vars]\n",
    "dtest = xgb.DMatrix(data)\n",
    "ypred = model.predict(dtest)\n",
    "\n",
    "# Make a long merged dataset to produce a gap-filled prediction of tropomi derived sfc no2\n",
    "merged_long = features.merge(target.drop_duplicates(subset=['datetime']),on='datetime', how='left')\n",
    "merged_long.fillna(value=np.nan, inplace=True)\n",
    "merged_long['gap_filled_tropomi'] = ypred / 10000\n",
    "merged_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bab123",
   "metadata": {},
   "source": [
    "### Gap-filling TROPOMI with the XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "merged_long.plot(x = 'datetime', y = cfTropBand, ax = ax, label = 'Tropospheric Column NO2') \n",
    "merged_long.plot.scatter(x = 'datetime', y = tropNo2Band, ax = ax, c = 'r', label = 'TROPOMI Observations', zorder=2)\n",
    "merged_long.plot(x = 'datetime', y = 'gap_filled_tropomi', ax = ax, c = 'k', label = 'prediction')\n",
    "ax.set_xlim([pd.to_datetime('2023-03-01'), pd.to_datetime('2023-06-01')])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73dea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Tropospheric NO2 from TROPOMI and Surface Observations from Open AQ\n",
    "\n",
    "merged_long_obs.rename(columns={tropNo2Band: 'TROPOMI Observations', cfTropBand: 'CF Tropospheric NO2'}, inplace=True)\n",
    "melty = pd.melt(merged_long_obs, id_vars='datetime', value_vars = ['TROPOMI Observations', 'CF Tropospheric NO2'], var_name='NO2 Value Source')\n",
    "\n",
    "fig = px.scatter(data_frame=melty, \n",
    "                    x='datetime', \n",
    "                    y='value', \n",
    "                    color = 'NO2 Value Source', \n",
    "                    title = 'Tropospheric NO2 Timeseries at Takoma Park, MD')\n",
    "fig.update_yaxes(title= 'Tropospheric NO2 (mol/m^2)', exponentformat='e')\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(font={'size':20}),\n",
    "    legend=dict(font={'size':16})\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_font={'size':18},\n",
    "                 tickfont=dict(size=16))\n",
    "fig.update_xaxes(title_font={'size':18},\n",
    "                 tickfont=dict(size=16),\n",
    "                range=['2023-01-01','2023-01-08'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469475d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Tropospheric NO2 from TROPOMI and Surface Observations from Open AQ\n",
    "\n",
    "merged_long_obs.rename(columns={tropNo2Band: 'TROPOMI Observations', cfTropBand: 'CF Tropospheric NO2', 'gap_filled_tropomi': 'Gap Filled TROPOMI'}, inplace=True)\n",
    "melty = pd.melt(merged_long_obs, id_vars='datetime', value_vars = ['TROPOMI Observations', 'CF Tropospheric NO2', 'Gap Filled TROPOMI'], var_name='NO2 Value Source')\n",
    "\n",
    "fig = px.scatter(data_frame=melty, \n",
    "                    x='datetime', \n",
    "                    y='value', \n",
    "                    color = 'NO2 Value Source', \n",
    "                    title = 'Tropospheric NO2 Timeseries at Takoma Park, MD')\n",
    "fig.update_yaxes(title= 'Tropospheric NO2 (mol/m^2)', exponentformat='e')\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(font={'size':20}),\n",
    "    legend=dict(font={'size':16})\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_font={'size':18},\n",
    "                 tickfont=dict(size=16))\n",
    "fig.update_xaxes(title_font={'size':18},\n",
    "                 tickfont=dict(size=16),\n",
    "                range=['2023-01-01','2023-01-08'])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfc189",
   "metadata": {},
   "source": [
    "### Creating Surface Data from TROPOMI Observations\n",
    "\n",
    "Using a ratio technique we can create a dataset of estimated surface NO2 from predicted TROPOMI observations.\n",
    "\n",
    "We will then compare those values to OpenAQ data for the same site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5505529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sfc(target, target_band):\n",
    "    target['sfc'] = target[target_band] * target[cfSurfBand] / target[cfTropBand]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_long = get_sfc(merged_long, 'gap_filled_tropomi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31887a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://api.openaq.org/v2/measurements?location_id=1704&parameter=no2&date_from=2022-03-01T08:37:22-04:00&date_to=2023-03-30T08:37:22-04:00&limit=100000\"\n",
    "url = f\"https://api.openaq.org/v2/measurements?location_id=1704&parameter=no2&date_from={cf_chm_subset.i_date}&date_to={cf_chm_subset.f_date}&limit=100000\"\n",
    "r = requests.get( url )\n",
    "assert(r.status_code==200)\n",
    "rs = r.json()['results']\n",
    "obs = pd.DataFrame()\n",
    "obs = pd.json_normalize(r.json()['results'])\n",
    "obs['datetime'] = [dt.datetime.strptime(i,'%Y-%m-%dT%H:%M:%S+00:00') for i in obs['date.utc']]\n",
    "obs['open_aq_value'] = obs['value'] * 1000\n",
    "obs['unit'] = 'ppb'\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#greater than the start date and smaller than the end date\n",
    "mask = (obs.datetime.max() >= merged_long.datetime) & (merged_long.datetime >= obs.datetime.min())\n",
    "\n",
    "obs_df = obs[['datetime', 'open_aq_value']]\n",
    "\n",
    "merged_long_obs = merged_long.loc[mask].merge(obs_df,on='datetime', how='left')\n",
    "merged_long_obs.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "merged_long_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963df464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Surface Derived NO2 from TROPOMI and Surface Observations from Open AQ\n",
    "\n",
    "merged_long_obs.rename(columns={'sfc': 'TROPOMI Derived Obs', 'open_aq_value': 'Open AQ'}, inplace=True)\n",
    "melty = pd.melt(merged_long_obs, id_vars='datetime', value_vars = ['TROPOMI Derived Obs', 'Open AQ'], var_name='NO2 Value Source')\n",
    "\n",
    "fig = px.scatter(data_frame=melty, \n",
    "                    x='datetime', \n",
    "                    y='value', \n",
    "                    color = 'NO2 Value Source', \n",
    "                    title = 'Surface NO2 Timeseries at Takoma Park, MD')\n",
    "fig.update_yaxes(title= 'Surface NO2 (ppb)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d01801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcuate RMSE for Two Data Sets\n",
    "\n",
    "diff = merged_long_obs['TROPOMI Derived Obs'] - merged_long_obs['Open AQ']\n",
    "rmse = np.square(diff).sum()/len(diff)\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f3bbc",
   "metadata": {},
   "source": [
    "### Creating GEOS-CF Forecasts from the XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3938f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset('https://tropomi.gesdisc.eosdis.nasa.gov/opendap/S5P_TROPOMI_Level2/S5P_L2__NO2____HiR.2/2023/276/S5P_OFFL_L2__NO2____20231003T005315_20231003T023444_30938_03_020500_20231004T164431.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd463b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "url = 'http://opendap.nccs.nasa.gov:80/dods/gmao/geos-cf/assim/chm_tavg_1hr_g1440x721_v36'\n",
    "url = 'http://opendap.nccs.nasa.gov:80/dods/gmao/geos-cf/assim/chm_tavg_1hr_g1440x721_v36'\n",
    "#url = 'https://opendap.nccs.nasa.gov/dods/gmao/geos-cf/assim/chm_tavg_1hr_g1440x721_v36'\n",
    "ds = xr.open_dataset(url, decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc66089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df748e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
